---
title: "R como SIG"
author: "Julián Equihua"
date: "28 de enero de 2016"
output: html_document
---

## Introducción

El análisis espacial y espacio-temporal es una extensión natural a las capacidades de R. Existen múltiples paquetes para manipular y analizar datos espacio-temporales en R. En esta clase vamos a dar una introducción a esto.

Primero que nada establezcamos el directorio de trabajo

```{r setup}

library("knitr")

opts_knit$set(root.dir = "/Users/agutierrez/Documents/curso_r_conabio/")

```


## Matrices y data frames

Recordando, una matriz es un arreglo bidimensional con una cierta cantidad de renglones y de columnas, por ejemplo un cuadrado de $3*3$ que contenga los números del 1 al 9

```{r}

matriz <- matrix(seq(1,9),nrow=3,ncol=3)

matriz

```

Un data.frame es también un arreglo con la diferencia de que puede contener más de un tipo de datos. Esto es, puede alojar texto, números y valores booleanos simultáneamente.

```{r}

numeros <- c(1,2,3)

texto <- c("hola","como","estas")

booleanos <- c(TRUE,FALSE,TRUE)

data_frame <- data.frame(numeros,texto,booleanos)

data_frame
```

Ambos tienen asociadas coordenadas de la forma $(renglón,columna)$ que comienzan de arriba a abajo y de izquierda a derecha. Estas permiten recuperar los valores que guardan, por ejemplo la entrada $(renglón,columna)=(2,1)$ para la matriz y el data.frame que definimos antes corresponden a:

```{r}

matriz[2,1]

data_frame[2,1]

```

También se pueden hacer búsquedas condicionales sobre estos objetos, esto es escribir en código peticiones como: dime qué valores de la primera columna de la matriz son mayores a 1.

Cuando se deja vacía una dimensión, R entiende que le estás pidiendo que incluya todos los valores existentes en ella. Por tanto, la pregunta ¿qué valores de la columna 1 de la matriz son mayores a 1? se expresa de la siguiente manera:

```{r}

condicion <- matriz[,1]>1

condicion


```

La primer columna está compuesta por los valores 1 (que claramente no es mayor a 1), 2 y 3 por lo tanto el resultado es FALSE, TRUE, TRUE.

La misma manera de hacerle "preguntas" a una matriz se puede lograr con un data.frame

```{r}

condicion <- data_frame[,1]>1

condicion


```

Algunas preguntas, por la naturaleza de los datos no tienen sentido. Por ejemplo de las palabras "hola", "como", "estas" ¿cuáles son mayores a 1?

## Rasters, primeros pasos

Un raster es simplemente una matriz de números qué tiene la intención de usarse como base para generar imágenes. A estos se les puede asociar una estructura espacial.

En R, existe el paquete "raster" que está ampliamente desarrollado y se recomienda como espina dorsal para cualquier análisis que incorpore imágenes de satélite.

La mayoría de las imágenes de satélite se pueden cargar usando la función raster(). Esta misma permite insertar una matriz en un objeto raster de R. 

```{r}

library("raster")

matriz_raster <- raster(matriz)

matriz_raster

```

Como podrá notarse, el objeto matriz_raster es ya un raster. Si bien, uno poco interesante y sin proyección.

Se mencionó que los rasters están pensados para ser la base de imágenes. El paquete "raster" contiene funcionalidades básicas de visualización de objetos raster.


```{r}

plot(matriz_raster)

```

Es muy importante observar que un objeto raster tiene asociados dos conjuntos de coordenadas. El objeto matriz_raster anterior se generó a partir de una matriz de dimensión $3*3$ por lo que está conformado por 9 píxeles que se ubican a través de su (renglón,columna). Por otro lado, define un espacio abstracto continuo localizado en el extent: 0, 1, 0, 1  (xmin, xmax, ymin, ymax). Por tanto la resolución (tamaño de cada píxel) del raster es de $0.333*0.333$.

En este contexto, los puntos son objetos espaciales sin área. Por lo que uno se puede localizar en cualquier lugar del espacio que definimos, por ejemplo en las coordenadas $(0.25,0.75)$

```{r}

plot(matriz_raster)

points(0.25,0.75,pch=21,bg="red",cex=2)

```

Utilizando el paquete "rasterVis" que es uno cuya intención primordial es visualizar rasters y sus análisis podemos visualizar este raster muy simple con los valores correspondientes a cada pixel. Esto permitirá observar el resultado de los siguientes procesos que llevaremos a cabo.

```{r}

library("ggplot2")
library("rasterVis")

gplot(matriz_raster) + geom_tile(aes(fill=values(matriz_raster))) + 
                  scale_colour_brewer(palette="Blues")  +
                  coord_equal() + 
                  geom_text(aes(label=sprintf("%02.0f",values(matriz_raster))),color="white",size=5)

```

Análogamente a como sucedía con la matriz, podemos recuperar el valor del raster en la entrada $(renglón,columna)=(2,1)$

```{r}

matriz_raster[2,1]

```

Un raster también es entendido en R como un vector de arriba a abajo y de izquierda a derecha. En este caso el arreglo tiene longitud 9 y la entrada $(renglón,columna)=(2,1)$ es igual a la entrada $[4]$.

```{r}

matriz_raster[4]

```

Lo anterior en combinación con expresiones condicionales nos permite hacer búsquedas y manipular rasters.

Podemos multiplicar el raster en su totalidad por 2 y restarle la constante 1.

```{r}

matriz_raster_por2_menos1 <- matriz_raster * 2 - 1

gplot(matriz_raster_por2_menos1) + geom_tile(aes(fill=values(matriz_raster_por2_menos1))) + 
                  scale_colour_brewer(palette="Blues")  +
                  coord_equal() + 
                  geom_text(aes(label=sprintf("%02.0f",values(matriz_raster_por2_menos1))),color="white",size=5)
```

Podemos reemplazar todos los píxeles del raster que cumplan la condición de ser mayores a 4 por 999. Esto se logra expresando la condición de manera análoga a como lo hicimos para matrices. Como un raster se puede ver como un vector, basta con meter la condición en una única dimensión

```{r}

# reemplazar matriz_raster donde matriz_raster mayor a 4 por 999
 matriz_raster[matriz_raster>4] <- 999

gplot(matriz_raster) + geom_tile(aes(fill=values(matriz_raster))) + 
                  scale_colour_brewer(palette="Blues")  +
                  coord_equal() + 
                  geom_text(aes(label=sprintf("%02.0f",values(matriz_raster))),color="white",size=5)
```

Hay funciones básicas en el paquete raster que son útiles en mútiples situaciones:

cellStats() calcula un estadístico definido por el usuario sobre un raster de entrada, por ejemplo se puede usar para obtener el promedio de matriz_raster

```{r}

cellStats(matriz_raster,stat="mean")

```

## Análisis de Rasters usando R

Como se indicó se puede cargar prácticamente cualquier raster utilizando la función raster(). Muchas imágenes satelitales son en realidad multiespectrales, esto quiere decir que en vez de ser una sola matriz son varias apiladas. Por ejemplo las imágenes RapidEye son imágenes constan de 5 bandas (green,blue,red, red edge, near infrared). Estas imágenes en particular se deben cargar con la función brick() o stack(). Carguemos un recorte de imagen RapidEye localizada en el estado de Chiapas. Si se llama al objeto se desplegarán los metadatos del mismo:

```{r}

chiapas1 <- brick(paste0(getwd(),"/1crop.tif"))

chiapas1

# visualizar las bandas RGB
plotRGB(chiapas1,r=3,g=2,b=1)

```

Utilizando la función subset() podemos obtener una o más bandas de una imagen multiespectral. Por ejemplo podemos extraer las bandas red (VIS) y near infrared (NIR).

```{r}

VIS <- subset(chiapas1,subset=3)

NIR <- subset(chiapas1,subset=5)

par(mfrow=c(1,2))

plot(VIS,main="VIS")
plot(NIR,main="NIR")

```

Utilizando los mecanismos de algebra de mapas descritos en la sección anterior podemos trivialmente calcular el NDVI de esta imagen.

$$
\begin{aligned}
NDVI := \frac{NIR-VIS}{NIR+VIS}
\end{aligned}
$$

```{r}

chiapas1_ndvi <- (NIR-VIS)/(NIR+VIS)

plot(chiapas1_ndvi,main="NDVI")

```

Utilizando algebra de mapas y la función cellStats() podemos estandarizar esta imagen. Le restaremos su media y dividiremos esto sobre la desviación estándar de la misma.

```{r}

chiapas1_ndvi_st <- (chiapas1_ndvi-cellStats(chiapas1_ndvi,stat="mean"))/(cellStats(chiapas1_ndvi,stat="sd"))

plot(chiapas1_ndvi_st,main="NDVI estandarizado")

```

Con base en el procedimiento anterior, tratemos de generar un ejercicio simple de detección de cambios. Tomemos una imagen RapidEye del mismo lugar pero tomada un año después que la que acabamos de trabajar. Llevemos a cabo el mismo procedimiento para obtener su NDVI estandarizado.

```{r}

chiapas2 <- brick(paste0(getwd(),"/2crop.tif"))

VIS <- subset(chiapas2,subset=3)

NIR <- subset(chiapas2,subset=5)

chiapas2_ndvi <- (NIR-VIS)/(NIR+VIS)

chiapas2_ndvi_st <- (chiapas2_ndvi-cellStats(chiapas2_ndvi,stat="mean"))/(cellStats(chiapas2_ndvi,stat="sd"))

plot(chiapas2_ndvi_st,main="NDVI estandarizado, 1 año después")

```

Ahora generaremos una imagen de diferencias, D, a partir de estas dos de NDVI.

$$
\begin{aligned}
D = NDVI_1 - NDVI_2
\end{aligned}
$$


```{r}

D <- chiapas1_ndvi_st - chiapas2_ndvi_st

plot(D,main="Diferencias en NDVI")

```

Aquí las diferencias positivas significan que el NDVI de la fecha 1 fue mayor al de la fecha 2. Diferencias negativas significan que el NDVI de la fecha 1 fue menor al de la fecha 2. Lo que dificulta el estudio de los cambios es que existe un continuo de magnitudes de diferencias. Naturalmente suponemos que diferencias de magnitud cercanas a $0$ deben considerarse no-cambios pero no es claro de qué magnitud debe ser una diferencia para poder tomarse como un cambio. Vamos a visualizar el histograma de las diferencias para darnos una idea de la distribución de estas.

```{r}

hist(D,breaks=100,main="Diferencias en NDVI",xlab="Diferencias",ylab="Conteos")

```

Parecería que la distribución de diferencias es aproximadamente normal. Se sabe que en una distribución normal, 95% de los valores se encuentran a 2 desviaciones estándar de su media. Tomando esto en cuenta definiremos como una diferencia significativa (cambio) a toda aquella que se encuentre a dos desviaciones estándar de la diferencia media. Podemos utilizar lo aprendido hasta ahora para condicionalmente reemplazar en la imagen de diferencias todo aquella que queremos descartar por ser una no-significativa.

```{r}

umbral_positivo <- cellStats(D,stat="mean")+ 2*cellStats(D,stat="sd")

umbral_negativo <- cellStats(D,stat="mean")- 2*cellStats(D,stat="sd")

# Recordatorio: se pueden combinar múltiples condiciones utilizando operadores lógicos
#
# El operador | se usa para expresar "o"
#
# El operador & se usa para expresar "y"

D[(D>umbral_negativo) & (D<umbral_positivo)] <-NA 

```

Este es el resultado final de este proceso. En R, es tan secillo escribir un raster como leerlo. Para este propósito se utiliza la función writeRaster()

```{r}

writeRaster(D, filename=paste0(getwd(),"/diferencias_significativas.tif"), format="GTiff", overwrite=TRUE)

``` 

![Resultado final.](/Users/agutierrez/Documents/repositories/r-conabio/05-sig_sdm/sig/images/dif_stack.jpg)

El paquete raster tiene funciones dedicadas a manejar la proyección de las capas con las que se está trabajando. Supongamos que queremos visualizar este último resultado en Google Earth. ¿está en la proyección correcta?

```{r}

projection(D)

``` 

NO.

```{r}

D_reproj <- projectRaster(D,crs=CRS("+proj=longlat"))

``` 

Luego simplemente generamos un KML con la funcón KML()

```{r}

KML(D_reproj,paste0(getwd(),"/cambios_kml"),maxpixels=1000000,overwrite=TRUE)

``` 

## Capas vectoriales, primeros pasos

Una Capa vectorial es una estructura espacial conformada por unidades (puntos, líneas o polígonos), asociada a una tabla de datos. 

La librería GDAL es una librería Open Source para leer y escribir formatos raster y vectoriales. El paquete rgdal es una interfaz a esta librería que permite la fácil lectura de Shape files en R.

```{r}

library("rgdal")

puntos <- readOGR(dsn=paste0(getwd(),"/puntos.shp"),layer="puntos")
lineas <- readOGR(dsn=paste0(getwd(),"/lineas.shp"),layer="lineas")
poligonos <- readOGR(dsn=paste0(getwd(),"/poligonos.shp"),layer="poligonos")

par(mfrow=c(1,3))

plot(puntos)
plot(lineas)
plot(poligonos)

``` 

Cargado un shape file en el espacio de trabajo de R, este se convierte en un data.frame espacial. Por lo que la mayoría de las funcionalidades disponibles para un data.frame aplican.

```{r}

# tipo de objeto
class(puntos)
class(lineas)
class(poligonos)

# cabeza de los datos
head(puntos)
head(lineas)
head(poligonos)

``` 

Se debe notar que por como están programadas estas estructuras espaciales en R, todo supconjunto de un data.frame espacial es nuevamente un data.frame espacial y se pueden generar subconjuntos utilizando los mecanismos usuales para data.frames

```{r}

# elegimos el primer polígono
poligono <- poligonos[1,]

class(poligono)

plot(poligono)

``` 

Como sucede con un data.frame usual se puede agregar una nueva columna (variable) a un data.frame espacial utilizando el signo "$".

```{r}

# agregamos al objetos poligonos la variable intensidad. Este objeto tiene 3 polígonos. Asignarémos un valor de intensidad = 0 al primer polígono, y un valor de intensidad = 2 a los siguientes 2. 
poligonos$intensidad <- c(1,2,2)

head(poligonos)

colores <- c("red","blue")

plot(poligonos,col=colores[poligonos$intensidad])

``` 

## Análisis de capas vectoriales usando R

Existen numerosas librerías para hacer análisis de capas vectoriales de puntos, líneas y polígonos.

Algo que es importante es entender cómo manipular distintas capas vectoriales simultáneamente, por lo que vale la pena leer las funciones disponibles en los paquetes más fundamentales: sp, maptools, raster, etc. 

Por ejemplo, es trivial encontrar las intersecciones espaciales entre polígonos y puntos utilizando la función over() del paquete sp.

```{r}

overlay <- over(puntos,poligonos)

overlay

plot(poligonos,col=colores[poligonos$intensidad])

plot(puntos,add=TRUE)


``` 

La función over() está programada para manejar de manera distinta cada una de los casos que surgen de las combinaciones de puntos, líneas y polígonos. Es recomendable consultar la ayuda de la función para entender cada caso (?over). En el caso de puntos vs polígonos la salida tiene tantas filas como puntos hay de entrada (11). Para cada fila de la salida se indica sobre qué polígono cae cada punto y cualquier otra variable que esté incluída en la tabla de datos de los polígonos (e.g. intensidad en este caso.)

Para determinar intersecciones complejas entre dos capas de polígonos es más conveniente utilizar el paquete raster.

```{r}

poligonos2 <- readOGR(dsn=paste0(getwd(),"/cruces.shp"),layer="cruces")

plot(poligonos2)

plot(poligonos,col=colores[poligonos$intensidad],add=TRUE)

intersecciones <- poligonos + poligonos2

data.frame(intersecciones)

plot(intersecciones,col=blues9)

``` 

## Juntando todo

La función extract() del paquete raster es una sumamente útil. Permite sobreponer un data.frame espacial sobre un raster y extraer los valores de píxeles sobre los que cae cada registro del data.frame espacial.

Cuando el data.frame espacial es uno de puntos entonces cada punto cae exáctamente sobre 1 pixel por lo que la extracción es trivial.

Si el data.frame espacial es, por ejemplo, uno de polígonos; entonces cada registro cae sobre un grupo de píxeles. En este caso, la función extract debe recibir una función para poder asociarle un valor a cada polígono. Por ejemplo, si se elige la funciòn promedio, cada polígono es asociado al promedio de píxeles que envuelve.

```{r}

# leamos un raster de altitud con resolución de 1 km
altitud <- raster(paste0(getwd(),"/dem30_mean1000.tif"))

plot(altitud)
plot(poligonos,col=colores[poligonos$intensidad],add=TRUE)
plot(puntos,add=TRUE)

extraccion_puntos <- extract(altitud,puntos)

# valor de altitud de cada punto
extraccion_puntos

extraccion_poligonos <- extract(altitud,poligonos,fun=mean,na.rm=TRUE)

# valor de altitud promedio por polígono
extraccion_poligonos

``` 

Podemos combinar múltiples funciones para lograr objetivos muy específicos. Por ejemplo, supongamos que queremos cortar el raster de altitud con base en nuestro shape de polígonos.


```{r}

 
extShape <- extent(poligonos)
img <- crop(altitud, extShape, snap='out')
img.NA <- setValues(img, NA)
img.mask <- rasterize(poligonos, img.NA)
img.crop <- mask(x=img, mask=img.mask)

plot(img.crop,main="Altitud en polígonos")

``` 

Ahora llevaremos a cabo un ejercicio en el que usaremos varias distintas funcionalidades de R para generar una regionalización del país de manera automatizada.

Tomemos el raster altitud como base.

Vamos a inicializar un raster multiespectral vacío y luego asignarle el raster de altitud como primera banda.

```{r}

# raster multiespectral vacío
brik <- brick()

# asignemos altitud como primera banda
brik <- addLayer(brik,altitud)

```

El raster multiespectral brik, hereda los metadatos de el raster altitud. Si queremos introducirle más bandas, estas tienen que compartir exactamente los mismos metadatos. Introduzcamos las variables % vegetacion boscosa, % vegetación no-boscosa, % de no-vegetación, temperatura máxima promedio, temperatura mínima promedio y precipitación promedio.

```{r}

v_boscosa <- raster(paste0(getwd(),"/MOD44B_2014-03-06.Percent_Tree_Cover.tif"))
v_noboscosa <- raster(paste0(getwd(),"/MOD44B_2014-03-06.Percent_NonTree_Vegetation.tif"))
v_no <- raster(paste0(getwd(),"/MOD44B_2014-03-06.Percent_NonVegetated.tif"))

# plot v_boscosa
plot(v_boscosa,main="% vegetación boscosa")

# ¿hay un match entre los metadatos de estas capas y el raster altitud?
projection(v_boscosa)==projection(altitud)
extent(v_boscosa)==extent(altitud)
res(v_boscosa)==res(altitud)

# resolución de v_boscosa?
res(v_boscosa)

```

Todo está harmonizado excepto la resolución de los rasters. Las tres capas de vegetación anteriores están generadas con base en imágenes modis de 250 m. Sabemos que nuestro raster de altitud tiene una resolución de 1000 m. Agreguemos estas capas por un factor de 4 con base en la función promedio. También observamos que estas capas se extienden más allá de la delimitación oficial de México. Usaremos el raster altitud para eliminar todo aquello que no corresponda con México. Luego podremos agregar las capas de vegetación como bandas nuevas a nuestro raster multiespectral.

```{r}

# agregación factor *4 con base en función promedio
v_boscosa <- aggregate(v_boscosa,fact=4,fun=mean,na.rm=TRUE)
v_noboscosa <- aggregate(v_noboscosa,fact=4,fun=mean,na.rm=TRUE)
v_no <- aggregate(v_no,fact=4,fun=mean,na.rm=TRUE)

# filtrado de capas: si es NA en altitud que sea NA en capas de vegetación
v_boscosa[is.na(altitud)]<-NA
v_noboscosa[is.na(altitud)]<-NA
v_no[is.na(altitud)]<-NA

# Introduzcamos estas capas a nuestro raster multiespectral
brik <- addLayer(brik,v_boscosa)
brik <- addLayer(brik,v_noboscosa)
brik <- addLayer(brik,v_no)

dim(brik)

```

Ahora simplemente agregaremos las capas que faltan al raster multiespectral: temperatura máxima promedio, temperatura mínima promedio y precipitación promedio

```{r}


# Agregamos las bandas que faltan
brik <- addLayer(brik,
                 raster(paste0(getwd(),"/temp_max.tif")))

brik <- addLayer(brik,
                 raster(paste0(getwd(),"/temp_min.tif")))

brik <- addLayer(brik,
                 raster(paste0(getwd(),"/precipitacion.tif")))


```

Empezamos discutiendo matrices y data.frames. Los data.frames son estructuras sumamente apropiadas para llevar a cabo análisis. Vamos a generar un data.frame a partir de nuestro raster multiespectral. Cada fila correspondrá a un pixel. Cada banda se hará una columna (variable), además de las coordenadas x, y. 

```{r}

# tabla de datos
tabla_datos <- rasterToPoints(brik)

# descartemos las filas no completas
tabla_datos_clean <- tabla_datos[complete.cases(tabla_datos),]

head(tabla_datos_clean)

```

Es evidente que estas variables deben estar correlacionadas. Generemos un análisis de componentes principales sobre estas variables sin tomar en cuenta las coordenadas.

```{r}

# cálculo de componentes principales
componentes <- prcomp(tabla_datos_clean[,2:9],center=TRUE,scale. =TRUE)

# varianza explicada
summary(componentes)

```

Ahora utilicemos 4 componentes principales para llevar a cabo un ejercicio de clustering usando k-medias

```{r}

# k-medias, k=10
kmedias <- kmeans(componentes$x[,1:4],centers=10,iter.max=50)

```

El resultado del clustering se lo podemos asociar a las coordenadas de nuestra matriz inicial. Luego convertir esta tabla en un objeto espacial y luego un raster.

```{r}

# clustering result
clustered_data <- data.frame(x=tabla_datos_clean[,1],
                             y=tabla_datos_clean[,2],
                             clust=kmedias$cluster)

# convertir esta tabla en un objeto espacial
coordinates(clustered_data)=~x+y
gridded(clustered_data)=TRUE
clustered_data<-raster(clustered_data)
projection(clustered_data)<-projection(altitud)

```

Finalmente podemos convertir este raster en una capa vectorial y guardarla en el disco duro.

```{r}

poligonos_clusters <- rasterToPolygons(clustered_data,n=4,dissolve=TRUE)

writeOGR(poligonos_clusters,paste0(getwd(),"/regionalizacion.shp"),
                        "regionalizacion",driver="ESRI Shapefile")

```

